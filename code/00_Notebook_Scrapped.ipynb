{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***NOTE: Even though this code block runs without error it was scrapped b/c I ran out of time. Instead of carefully removing the minimum amount of data and including entries with a title, but no selftext, I will focus on a complete data set w/ both selftext AND title. I have far more data than the project requires so I can be more thorough in the future when I have more time.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Essentially this dictionary's keys are dupicate selftext and \n",
    "# the values are the No. times it appears in data\n",
    "duplicate_title = {}\n",
    "# max_duplicate 615 was chosen to reduce comutation time as I manually observed there were \n",
    "# only 615 unique selftext submissions with duplicates\n",
    "max_duplicate = 615\n",
    "for i in range(max_duplicate):\n",
    "    if suicide_df.title.value_counts()[i] > 1:\n",
    "        duplicate_title[suicide_df.title.value_counts().index[i]] = suicide_df.title.value_counts()[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code removed 1,889 rows with useless selftext which also were known duplicates in the title column\n",
    "drop_rows = []\n",
    "# Create a df of selftext entries equal to: [deleted], [removed], or null\n",
    "delete_remove_na = suicide_df[(suicide_df.selftext == '[deleted]') | \n",
    "                        (suicide_df.selftext == '[removed]') | \n",
    "                        (suicide_df.selftext.isnull())\n",
    "                        ]\n",
    "# Look through every entry in delete_remove_na\n",
    "for i in list(delete_remove_na.index):\n",
    "    # Check to see if any of the titles are in the duplicates dictionary\n",
    "    if delete_remove_na.title[i] in list(duplicate_title.keys()):\n",
    "        # Double-check that you haven't already removed all duplicates\n",
    "        if duplicate_title[ delete_remove_na.title[i] ] > 1:\n",
    "            # Add index to list of rows to drop\n",
    "            drop_rows.append(i)\n",
    "            # Reduce No. of duplicates in duplicate dictionary by one(so you at least keep one!)\n",
    "            duplicate_title[delete_remove_na.title[i]] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code was used to categorize top words in Notebook 04, but in the end wasn't helpful \n",
    "text_and_subredditwords = []\n",
    "maybes =[]\n",
    "for word in tops:\n",
    "    if word in stops:\n",
    "        my_stop_words.append(word)\n",
    "    else:\n",
    "        maybes.append(word)\n",
    "len(my_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code block was intended to be used to identify stop-words sure to improve the model accuracy, nope!\n",
    "# After investigating stop words it became apparant that the best scores were with \n",
    "# CountVectorizers standard set of 'english' stop words\n",
    "STOPS = list(CountVectorizer(stop_words = 'english').get_stop_words())\n",
    "print(f'No. of Stop Words in C-Vec: {len(stops_cvec)}')\n",
    "\n",
    "print(f'No. of top 500 Words in both subreddits: {len(both)}')\n",
    "stop_words_in_both = []\n",
    "stop_words_in_both4 = []\n",
    "subject_stop_words = []\n",
    "for word in both:\n",
    "    if word in STOPS:\n",
    "        stop_words_in_both.append(word)\n",
    "    else:\n",
    "        subject_stop_words.append(word)\n",
    "print(f'No. of top 500 Stop Words in both subreddits: {len(stop_words_in_both)}')\n",
    "print(f'No. of top 500 subject specific Stop Words appearing in both subreddits: {len(subject_stop_words)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
